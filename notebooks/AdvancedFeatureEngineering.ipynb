{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53e7230",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering (TMDB 2010-2025)\n",
    "\n",
    "This notebook builds on the base feature engineering work and adds **advanced features** that can improve\n",
    "model performance for predicting movie success/popularity.\n",
    "\n",
    "**New features created:**\n",
    "- Holiday & seasonal release flags\n",
    "- Release competition density (movies released same month)\n",
    "- Director historical track record (avg revenue, avg rating)\n",
    "- Franchise / sequel indicators\n",
    "- Budget tier categorization\n",
    "- Cast diversity index\n",
    "- Overview sentiment & readability features\n",
    "\n",
    "**Output:** `data/data_advanced_features.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf237fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned/engineered dataset from the base pipeline\n",
    "df = pd.read_csv(\"../data/data_cleaned_engineered.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55820cef",
   "metadata": {},
   "source": [
    "## 1. Seasonality & Holiday Release Features\n",
    "\n",
    "Movies released around holidays (Christmas, summer, Thanksgiving) often have different box-office dynamics.\n",
    "We create flags for key release windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "df[\"release_month\"] = df[\"release_date\"].dt.month\n",
    "df[\"release_day\"] = df[\"release_date\"].dt.day\n",
    "\n",
    "# Summer blockbuster season (May-August)\n",
    "df[\"is_summer_release\"] = df[\"release_month\"].isin([5, 6, 7, 8]).astype(int)\n",
    "\n",
    "# Holiday season (Nov 15 - Dec 31)\n",
    "df[\"is_holiday_release\"] = (\n",
    "    ((df[\"release_month\"] == 11) & (df[\"release_day\"] >= 15)) |\n",
    "    (df[\"release_month\"] == 12)\n",
    ").astype(int)\n",
    "\n",
    "# Valentine's Day window (Feb 7-14)\n",
    "df[\"is_valentines_release\"] = (\n",
    "    (df[\"release_month\"] == 2) & (df[\"release_day\"].between(7, 14))\n",
    ").astype(int)\n",
    "\n",
    "# Halloween window (Oct 15-31)\n",
    "df[\"is_halloween_release\"] = (\n",
    "    (df[\"release_month\"] == 10) & (df[\"release_day\"] >= 15)\n",
    ").astype(int)\n",
    "\n",
    "# January \"dump month\" (studios release weaker films in Jan)\n",
    "df[\"is_dump_month\"] = (df[\"release_month\"] == 1).astype(int)\n",
    "\n",
    "print(\"Seasonal flags distribution:\")\n",
    "for col in [\"is_summer_release\", \"is_holiday_release\", \"is_valentines_release\", \"is_halloween_release\", \"is_dump_month\"]:\n",
    "    print(f\"  {col}: {df[col].sum()} movies ({df[col].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef761b6f",
   "metadata": {},
   "source": [
    "## 2. Release Competition Density\n",
    "\n",
    "How many other movies were released in the same month/year? High competition can dilute box-office performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count movies released in the same year-month\n",
    "df[\"release_year\"] = df[\"release_date\"].dt.year\n",
    "df[\"year_month\"] = df[\"release_date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "month_counts = df.groupby(\"year_month\").size().rename(\"monthly_competition\")\n",
    "df = df.merge(month_counts, left_on=\"year_month\", right_index=True, how=\"left\")\n",
    "\n",
    "# Competition within the same week\n",
    "df[\"year_week\"] = df[\"release_date\"].dt.strftime(\"%Y-W%U\")\n",
    "week_counts = df.groupby(\"year_week\").size().rename(\"weekly_competition\")\n",
    "df = df.merge(week_counts, left_on=\"year_week\", right_index=True, how=\"left\")\n",
    "\n",
    "print(f\"Monthly competition — mean: {df['monthly_competition'].mean():.1f}, max: {df['monthly_competition'].max()}\")\n",
    "print(f\"Weekly competition  — mean: {df['weekly_competition'].mean():.1f}, max: {df['weekly_competition'].max()}\")\n",
    "\n",
    "# Drop helper columns\n",
    "df.drop(columns=[\"year_month\", \"year_week\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66608857",
   "metadata": {},
   "source": [
    "## 3. Director Historical Track Record\n",
    "\n",
    "A director's past performance is a strong signal for future movies. We compute rolling averages\n",
    "of revenue, vote_average, and popularity up to (but not including) the current film to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de76b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by director and release date\n",
    "df = df.sort_values([\"director_name\", \"release_date\"]).reset_index(drop=True)\n",
    "\n",
    "# For each director, compute expanding mean of past movies (excluding current)\n",
    "def director_rolling_features(group):\n",
    "    \"\"\"Compute expanding mean of past movies for each director.\"\"\"\n",
    "    result = pd.DataFrame(index=group.index)\n",
    "    \n",
    "    for col in [\"revenue\", \"vote_average\", \"popularity\"]:\n",
    "        if col in group.columns:\n",
    "            # Shift by 1 to exclude the current row, then expanding mean\n",
    "            result[f\"director_hist_{col}\"] = group[col].shift(1).expanding().mean()\n",
    "    \n",
    "    # Count of prior films by this director\n",
    "    result[\"director_film_count\"] = range(len(group))\n",
    "    \n",
    "    return result\n",
    "\n",
    "director_features = df.groupby(\"director_name\", group_keys=False).apply(director_rolling_features)\n",
    "df = pd.concat([df, director_features], axis=1)\n",
    "\n",
    "# Flag for first-time directors (no track record)\n",
    "df[\"is_debut_director\"] = (df[\"director_film_count\"] == 0).astype(int)\n",
    "\n",
    "print(f\"Debut directors: {df['is_debut_director'].sum()} ({df['is_debut_director'].mean()*100:.1f}%)\")\n",
    "print(f\"Director historical revenue — mean: {df['director_hist_revenue'].mean():.0f}\")\n",
    "print(f\"Director historical rating  — mean: {df['director_hist_vote_average'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91b0c6",
   "metadata": {},
   "source": [
    "## 4. Franchise & Sequel Detection\n",
    "\n",
    "Sequels and franchise films generally have higher built-in audiences. We detect them using\n",
    "title patterns and keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c36838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list_column(x):\n",
    "    \"\"\"Safely parse string representations of lists.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(str(x))\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# Parse keywords if stored as strings\n",
    "if \"keywords\" in df.columns:\n",
    "    df[\"keywords\"] = df[\"keywords\"].map(parse_list_column)\n",
    "\n",
    "# Sequel detection via keywords\n",
    "sequel_keywords = {\"sequel\", \"franchise\", \"series\", \"trilogy\", \"prequel\", \"reboot\", \"remake\", \"spin-off\"}\n",
    "df[\"is_franchise_keyword\"] = df[\"keywords\"].map(\n",
    "    lambda kws: int(any(k.lower() in sequel_keywords for k in kws))\n",
    ")\n",
    "\n",
    "# Sequel detection via title patterns (e.g., \"Part 2\", \"Chapter 3\", Roman numerals)\n",
    "sequel_patterns = [\n",
    "    r'\\b(part|chapter|vol\\.?|volume)\\s*\\d+',\n",
    "    r'\\b[IVX]{2,}\\b',           # Roman numerals (II, III, IV, etc.)\n",
    "    r'\\d{1,2}\\s*$',             # Ends with a number (e.g., \"Toy Story 3\")\n",
    "    r':\\s*.+$',                  # Has a subtitle after colon (common in sequels)\n",
    "]\n",
    "\n",
    "def detect_sequel_title(title):\n",
    "    if pd.isna(title):\n",
    "        return 0\n",
    "    for pattern in sequel_patterns[:3]:  # Use only clear sequel patterns\n",
    "        if re.search(pattern, str(title), re.IGNORECASE):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df[\"is_sequel_title\"] = df[\"title\"].map(detect_sequel_title)\n",
    "\n",
    "# Combined franchise flag\n",
    "df[\"is_franchise\"] = ((df[\"is_franchise_keyword\"] == 1) | (df[\"is_sequel_title\"] == 1)).astype(int)\n",
    "\n",
    "print(f\"Franchise/sequel movies: {df['is_franchise'].sum()} ({df['is_franchise'].mean()*100:.1f}%)\")\n",
    "print(f\"  - By keyword: {df['is_franchise_keyword'].sum()}\")\n",
    "print(f\"  - By title pattern: {df['is_sequel_title'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79436e9b",
   "metadata": {},
   "source": [
    "## 5. Budget Tier Categorization\n",
    "\n",
    "Raw budget values span orders of magnitude. Binning into tiers (micro, low, medium, high, blockbuster)\n",
    "can capture non-linear effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f945a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_budget(budget):\n",
    "    \"\"\"Categorize movie budgets into industry-standard tiers.\"\"\"\n",
    "    if pd.isna(budget) or budget <= 0:\n",
    "        return \"unknown\"\n",
    "    elif budget < 1_000_000:\n",
    "        return \"micro\"          # < $1M\n",
    "    elif budget < 15_000_000:\n",
    "        return \"low\"            # $1M - $15M\n",
    "    elif budget < 50_000_000:\n",
    "        return \"medium\"         # $15M - $50M\n",
    "    elif budget < 150_000_000:\n",
    "        return \"high\"           # $50M - $150M\n",
    "    else:\n",
    "        return \"blockbuster\"    # $150M+\n",
    "\n",
    "df[\"budget_tier\"] = df[\"budget\"].map(categorize_budget)\n",
    "\n",
    "# One-hot encode budget tiers\n",
    "budget_dummies = pd.get_dummies(df[\"budget_tier\"], prefix=\"budget_tier\")\n",
    "df = pd.concat([df, budget_dummies], axis=1)\n",
    "\n",
    "print(\"Budget tier distribution:\")\n",
    "print(df[\"budget_tier\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901e211",
   "metadata": {},
   "source": [
    "## 6. Cast Diversity Index\n",
    "\n",
    "Gender diversity in the cast is a meaningful signal. We compute a simple diversity index\n",
    "based on gender representation among the top 5 actors + director."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e82893",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_cols = [\"director_gender\", \"actor1_gender\", \"actor2_gender\", \n",
    "               \"actor3_gender\", \"actor4_gender\", \"actor5_gender\"]\n",
    "existing_gender_cols = [c for c in gender_cols if c in df.columns]\n",
    "\n",
    "def compute_gender_diversity(row):\n",
    "    \"\"\"Shannon entropy-based diversity index for gender representation.\"\"\"\n",
    "    genders = [row[c] for c in existing_gender_cols if pd.notna(row[c]) and row[c] > 0]\n",
    "    if len(genders) == 0:\n",
    "        return 0.0\n",
    "    counts = Counter(genders)\n",
    "    total = sum(counts.values())\n",
    "    probs = [c / total for c in counts.values()]\n",
    "    # Shannon entropy (normalized to [0,1])\n",
    "    entropy = -sum(p * np.log2(p) for p in probs if p > 0)\n",
    "    max_entropy = np.log2(len(counts)) if len(counts) > 1 else 1.0\n",
    "    return entropy / max_entropy if max_entropy > 0 else 0.0\n",
    "\n",
    "df[\"cast_gender_diversity\"] = df.apply(compute_gender_diversity, axis=1)\n",
    "\n",
    "# Female representation ratio\n",
    "if \"gender_female_count\" in df.columns and \"cast_size\" in df.columns:\n",
    "    total_people = df[\"cast_size\"] + 1  # include director\n",
    "    df[\"female_ratio\"] = df[\"gender_female_count\"] / total_people.replace(0, np.nan)\n",
    "\n",
    "print(f\"Cast gender diversity — mean: {df['cast_gender_diversity'].mean():.3f}, std: {df['cast_gender_diversity'].std():.3f}\")\n",
    "print(f\"Female ratio          — mean: {df['female_ratio'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29179a82",
   "metadata": {},
   "source": [
    "## 7. Overview Text Features\n",
    "\n",
    "Extract additional signals from the movie overview text: word complexity, presence of\n",
    "emotionally charged words, and question marks (which may signal mystery/thriller)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features(text):\n",
    "    \"\"\"Extract text-based features from overview.\"\"\"\n",
    "    if pd.isna(text) or str(text).strip() == \"\":\n",
    "        return pd.Series({\n",
    "            \"avg_word_length\": 0,\n",
    "            \"long_word_ratio\": 0,\n",
    "            \"has_question\": 0,\n",
    "            \"exclamation_count\": 0,\n",
    "            \"sentence_count\": 0,\n",
    "        })\n",
    "    \n",
    "    text = str(text)\n",
    "    words = text.split()\n",
    "    word_lengths = [len(w.strip('.,!?;:\"')) for w in words]\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"avg_word_length\": np.mean(word_lengths) if word_lengths else 0,\n",
    "        \"long_word_ratio\": sum(1 for l in word_lengths if l > 7) / max(len(word_lengths), 1),\n",
    "        \"has_question\": int(\"?\" in text),\n",
    "        \"exclamation_count\": text.count(\"!\"),\n",
    "        \"sentence_count\": len(re.split(r'[.!?]+', text.strip())),\n",
    "    })\n",
    "\n",
    "if \"overview\" in df.columns:\n",
    "    text_feats = df[\"overview\"].apply(text_features)\n",
    "    df = pd.concat([df, text_feats], axis=1)\n",
    "    \n",
    "    print(\"Text features summary:\")\n",
    "    for col in text_feats.columns:\n",
    "        print(f\"  {col} — mean: {df[col].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af33788",
   "metadata": {},
   "source": [
    "## 8. Genre Interaction Features\n",
    "\n",
    "Certain genre combinations work differently. We create interaction features for common\n",
    "genre pairings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define meaningful genre interaction pairs\n",
    "genre_interactions = [\n",
    "    (\"genre_action\", \"genre_comedy\", \"genre_action_x_comedy\"),\n",
    "    (\"genre_action\", \"genre_science_fiction\", \"genre_action_x_scifi\"),\n",
    "    (\"genre_horror\", \"genre_comedy\", \"genre_horror_x_comedy\"),\n",
    "    (\"genre_drama\", \"genre_romance\", \"genre_drama_x_romance\"),\n",
    "    (\"genre_action\", \"genre_adventure\", \"genre_action_x_adventure\"),\n",
    "    (\"genre_animation\", \"genre_family\", \"genre_animation_x_family\"),\n",
    "    (\"genre_crime\", \"genre_thriller\", \"genre_crime_x_thriller\"),\n",
    "]\n",
    "\n",
    "for g1, g2, name in genre_interactions:\n",
    "    if g1 in df.columns and g2 in df.columns:\n",
    "        df[name] = (df[g1] * df[g2]).astype(int)\n",
    "\n",
    "print(\"Genre interaction features created:\")\n",
    "for _, _, name in genre_interactions:\n",
    "    if name in df.columns:\n",
    "        print(f\"  {name}: {df[name].sum()} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f3a08",
   "metadata": {},
   "source": [
    "## 9. Popularity-to-Votes Ratio\n",
    "\n",
    "This ratio can indicate whether a movie's visibility (popularity) is driven by actual viewer\n",
    "engagement (votes) or by marketing/hype alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"popularity\" in df.columns and \"vote_count\" in df.columns:\n",
    "    # Avoid division by zero\n",
    "    df[\"popularity_per_vote\"] = df[\"popularity\"] / df[\"vote_count\"].replace(0, np.nan)\n",
    "    df[\"log_vote_count\"] = np.log1p(df[\"vote_count\"])\n",
    "    \n",
    "    # High-hype flag: high popularity but low votes\n",
    "    pop_median = df[\"popularity\"].median()\n",
    "    vote_median = df[\"vote_count\"].median()\n",
    "    df[\"is_high_hype_low_engagement\"] = (\n",
    "        (df[\"popularity\"] > pop_median) & (df[\"vote_count\"] < vote_median)\n",
    "    ).astype(int)\n",
    "    \n",
    "    print(f\"Popularity per vote — mean: {df['popularity_per_vote'].mean():.4f}\")\n",
    "    print(f\"High hype, low engagement: {df['is_high_hype_low_engagement'].sum()} movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23cee4",
   "metadata": {},
   "source": [
    "## 10. Summary & Export\n",
    "\n",
    "Review the new features and save the enhanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all new features added in this notebook\n",
    "base_cols = pd.read_csv(\"../data/data_cleaned_engineered.csv\", nrows=0).columns.tolist()\n",
    "new_cols = [c for c in df.columns if c not in base_cols]\n",
    "\n",
    "print(f\"\\nTotal features added: {len(new_cols)}\")\n",
    "print(\"\\nNew features:\")\n",
    "for i, col in enumerate(new_cols, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95034ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enhanced dataset\n",
    "out_path = \"../data/data_advanced_features.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"Saved enhanced dataset to: {out_path}\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
